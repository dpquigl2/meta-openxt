diff -rupN valgrind-3.10.1.orig/coregrind/m_syswrap/syswrap-linux.c valgrind-3.10.1/coregrind/m_syswrap/syswrap-linux.c
--- valgrind-3.10.1.orig/coregrind/m_syswrap/syswrap-linux.c	2015-05-08 14:48:32.690977029 -0400
+++ valgrind-3.10.1/coregrind/m_syswrap/syswrap-linux.c	2015-05-08 14:50:21.027977017 -0400
@@ -7138,6 +7138,16 @@ PRE(sys_ioctl)
       break;
    }
 
+   case VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR: {
+       struct vki_xen_privcmd_mmapcacheattr *args =
+           (struct vki_xen_privcmd_mmapcacheattr *)(ARG3);
+       PRE_MEM_READ("VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR(addr)",
+                    (Addr)&args->addr, sizeof(args->addr));
+       PRE_MEM_READ("VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR(type)",
+                    (Addr)args->type, sizeof(args->type));
+      break;
+   }
+
    case VKI_XEN_IOCTL_EVTCHN_BIND_VIRQ: {
          struct vki_xen_ioctl_evtchn_bind_virq *args =
             (struct vki_xen_ioctl_evtchn_bind_virq *)(ARG3);
@@ -9433,6 +9443,7 @@ POST(sys_ioctl)
       }
       break;
 
+   case VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR:
    case VKI_XEN_IOCTL_EVTCHN_BIND_VIRQ:
    case VKI_XEN_IOCTL_EVTCHN_BIND_INTERDOMAIN:
    case VKI_XEN_IOCTL_EVTCHN_BIND_UNBOUND_PORT:
diff -rupN valgrind-3.10.1.orig/coregrind/m_syswrap/syswrap-xen.c valgrind-3.10.1/coregrind/m_syswrap/syswrap-xen.c
--- valgrind-3.10.1.orig/coregrind/m_syswrap/syswrap-xen.c	2015-05-08 14:48:32.684977029 -0400
+++ valgrind-3.10.1/coregrind/m_syswrap/syswrap-xen.c	2015-05-08 14:50:21.028977017 -0400
@@ -202,6 +202,19 @@ PRE(memory_op)
    case VKI_XENMEM_get_sharing_shared_pages:
       break;
 
+   case VKI_XENMEM_translate_gpfn_list: {
+      struct vki_xen_translate_gpfn_list *arg =
+          (struct vki_xen_translate_gpfn_list *)(unsigned int)ARG2;
+
+      PRE_MEM_READ("XENMEM_translate_gpfn_list domid",
+                   (Addr)&arg->domid, sizeof(arg->domid));
+      PRE_MEM_READ("XENMEM_translate_gpfn_list nr_gpfns",
+                   (Addr)&arg->nr_gpfns, sizeof(arg->nr_gpfns));
+      PRE_MEM_READ("XENMEM_translate_gpfn_list gpfn_list",
+                   (Addr)&arg->gpfn_list, sizeof(arg->gpfn_list));
+       break;
+   }
+
    case VKI_XENMEM_access_op: {
        struct vki_xen_mem_event_op *arg =
             (struct vki_xen_mem_event_op *)ARG2;
@@ -825,6 +838,21 @@ PRE(domctl)
       PRE_XEN_DOMCTL_READ(debug_op, vcpu);
       break;
 
+   case VKI_XEN_DOMCTL_test_assign_device:
+     __PRE_XEN_DOMCTL_READ(test_assign_device, assign_device, machine_sbdf);
+     break;
+
+   case VKI_XEN_DOMCTL_iommu_map_batch:
+     PRE_XEN_DOMCTL_READ(iommu_map_batch, gfn);
+     PRE_XEN_DOMCTL_READ(iommu_map_batch, nr);
+     break;
+
+   case VKI_XEN_DOMCTL_pin_mem_cacheattr:
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, start);
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, end);
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, type);
+     break;
+
    default:
       bad_subop(tid, layout, arrghs, status, flags,
                 "__HYPERVISOR_domctl", domctl->cmd);
@@ -834,6 +862,59 @@ PRE(domctl)
 #undef __PRE_XEN_DOMCTL_READ
 }
 
+PRE(sched_op)
+{
+   unsigned long op = ARG1;
+   void *arg = (void *)(unsigned long)ARG2;
+
+   PRINT("__HYPERVISOR_sched_op ( %ld, %p )", op, arg);
+
+#define __PRE_XEN_SCHEDOP_READ(_sched_op, _type, _field)    \
+   PRE_MEM_READ("XEN_SCHEDOP_" # _sched_op "." #_field,     \
+                (Addr)&((_type*)arg)->_field,               \
+                sizeof(((_type*)arg)->_field))
+#define PRE_XEN_SCHEDOP_READ(_sched_op, _field) \
+   __PRE_XEN_SCHEDOP_READ(_sched_op, struct vki_xen_sched_ ## _sched_op, _field)
+
+   switch (op) {
+   case VKI_XEN_SCHEDOP_yield:
+   case VKI_XEN_SCHEDOP_block:
+      /* No input argument. */
+      break;
+
+   case VKI_XEN_SCHEDOP_shutdown:
+      PRE_XEN_SCHEDOP_READ(shutdown, reason);
+      break;
+
+   case VKI_XEN_SCHEDOP_poll:
+      PRE_XEN_SCHEDOP_READ(poll, ports);
+      PRE_XEN_SCHEDOP_READ(poll, nr_ports);
+      PRE_XEN_SCHEDOP_READ(poll, timeout);
+      break;
+
+   case VKI_XEN_SCHEDOP_remote_shutdown:
+      PRE_XEN_SCHEDOP_READ(remote_shutdown, domain_id);
+      PRE_XEN_SCHEDOP_READ(remote_shutdown, reason);
+      break;
+
+   case VKI_XEN_SCHEDOP_shutdown_code:
+      /* No input argument. */
+      break;
+
+   case VKI_XEN_SCHEDOP_watchdog:
+      PRE_XEN_SCHEDOP_READ(watchdog, timeout);
+      break;
+
+   default:
+      bad_subop(tid, layout, arrghs, status, flags,
+                "__HYPERVISOR_sched_op", op);
+      break;
+   }
+
+#undef PRE_XEN_SCHEDOP_READ
+#undef __PRE_XEN_SHCEDOP_READ
+}
+
 PRE(hvm_op)
 {
    unsigned long op = ARG1;
@@ -842,11 +923,11 @@ PRE(hvm_op)
    PRINT("__HYPERVISOR_hvm_op ( %ld, %p )", op, arg);
 
 #define __PRE_XEN_HVMOP_READ(_hvm_op, _type, _field)    \
-   PRE_MEM_READ("XEN_HVMOP_" # _hvm_op " " #_field,     \
+   PRE_MEM_READ("XEN_HVMOP_" # _hvm_op "." #_field,     \
                 (Addr)&((_type*)arg)->_field,           \
                 sizeof(((_type*)arg)->_field))
 #define PRE_XEN_HVMOP_READ(_hvm_op, _field)                             \
-   __PRE_XEN_HVMOP_READ(_hvm_op, vki_xen_hvm_ ## _hvm_op ## _t, _field)
+   __PRE_XEN_HVMOP_READ(_hvm_op, struct vki_xen_hvm_ ## _hvm_op, _field)
 
    switch (op) {
    case VKI_XEN_HVMOP_set_param:
@@ -907,6 +988,107 @@ PRE(hvm_op)
        PRE_XEN_HVMOP_READ(inject_trap, cr2);
        break;
 
+   case VKI_XEN_HVMOP_set_isa_irq_level:
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, domid);
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, isa_irq);
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, level);
+      break;
+
+   case VKI_XEN_HVMOP_set_pci_link_route:
+      PRE_XEN_HVMOP_READ(set_pci_link_route, domid);
+      PRE_XEN_HVMOP_READ(set_pci_link_route, link);
+      PRE_XEN_HVMOP_READ(set_pci_link_route, isa_irq);
+      break;
+
+   case VKI_XEN_HVMOP_track_dirty_vram:
+      PRE_XEN_HVMOP_READ(track_dirty_vram, domid);
+      PRE_XEN_HVMOP_READ(track_dirty_vram, first_pfn);
+      PRE_XEN_HVMOP_READ(track_dirty_vram, nr);
+      break;
+
+   case VKI_XEN_HVMOP_modified_memory:
+      PRE_XEN_HVMOP_READ(modified_memory, domid);
+      PRE_XEN_HVMOP_READ(modified_memory, first_pfn);
+      PRE_XEN_HVMOP_READ(modified_memory, nr);
+      break;
+
+   case VKI_XEN_HVMOP_set_mem_type:
+      PRE_XEN_HVMOP_READ(set_mem_type, domid);
+      PRE_XEN_HVMOP_READ(set_mem_type, hvmmem_type);
+      PRE_XEN_HVMOP_READ(set_mem_type, nr);
+      PRE_XEN_HVMOP_READ(set_mem_type, first_pfn);
+      break;
+
+   case VKI_XEN_HVMOP_pagetable_dying:
+      PRE_XEN_HVMOP_READ(pagetable_dying, domid);
+      PRE_XEN_HVMOP_READ(pagetable_dying, gpa);
+      break;
+
+   case VKI_XEN_HVMOP_get_time:
+      /* No input argument */
+      break;
+
+   case VKI_XEN_HVMOP_xentrace:
+      PRE_XEN_HVMOP_READ(xentrace, event);
+      //__PRE_XEN_HVMOP_READ(xentrace, struct vki_xen_hvm_xentrace, extra_bytes);
+      break;
+
+   case VKI_XEN_HVMOP_set_mem_access:
+      PRE_XEN_HVMOP_READ(set_mem_access, domid);
+      PRE_XEN_HVMOP_READ(set_mem_access, hvmmem_access);
+      PRE_XEN_HVMOP_READ(set_mem_access, nr);
+      PRE_XEN_HVMOP_READ(set_mem_access, first_pfn);
+      break;
+
+   case VKI_XEN_HVMOP_get_mem_access:
+      PRE_XEN_HVMOP_READ(get_mem_access, domid);
+      PRE_XEN_HVMOP_READ(get_mem_access, pfn);
+      break;
+
+   case VKI_XEN_HVMOP_inject_trap:
+      PRE_XEN_HVMOP_READ(inject_trap, domid);
+      PRE_XEN_HVMOP_READ(inject_trap, vcpuid);
+      PRE_XEN_HVMOP_READ(inject_trap, vector);
+      PRE_XEN_HVMOP_READ(inject_trap, type);
+      PRE_XEN_HVMOP_READ(inject_trap, error_code);
+      PRE_XEN_HVMOP_READ(inject_trap, insn_len);
+      PRE_XEN_HVMOP_READ(inject_trap, cr2);
+      break;
+
+   case VKI_XEN_HVMOP_register_ioreq_server:
+      PRE_XEN_HVMOP_READ(register_ioreq_server, domid);
+      break;
+
+   case VKI_XEN_HVMOP_get_ioreq_server_buf_channel:
+      PRE_XEN_HVMOP_READ(get_ioreq_server_buf_channel, domid);
+      PRE_XEN_HVMOP_READ(get_ioreq_server_buf_channel, id);
+      break;
+
+   case VKI_XEN_HVMOP_map_io_range_to_ioreq_server:
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, domid);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, is_mmio);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, id);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, s);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, e);
+      break;
+
+   case VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server:
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, domid);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, is_mmio);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, id);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, addr);
+      break;
+
+   case VKI_XEN_HVMOP_register_pcidev:
+      PRE_XEN_HVMOP_READ(register_pcidev, domid);
+      PRE_XEN_HVMOP_READ(register_pcidev, id);
+      PRE_XEN_HVMOP_READ(register_pcidev, domain);
+      PRE_XEN_HVMOP_READ(register_pcidev, bus);
+      PRE_XEN_HVMOP_READ(register_pcidev, device);
+      PRE_XEN_HVMOP_READ(register_pcidev, function);
+      break;
+
+
    default:
       bad_subop(tid, layout, arrghs, status, flags,
                 "__HYPERVISOR_hvm_op", op);
@@ -975,6 +1157,7 @@ POST(memory_op)
 {
    switch (ARG1) {
    case VKI_XENMEM_maximum_ram_page:
+   case VKI_XENMEM_add_to_physmap:
    case VKI_XENMEM_set_memory_map:
    case VKI_XENMEM_decrease_reservation:
    case VKI_XENMEM_claim_pages:
@@ -1013,6 +1196,14 @@ POST(memory_op)
    case VKI_XENMEM_get_sharing_shared_pages:
        /* No outputs */
        break;
+
+   case VKI_XENMEM_translate_gpfn_list: {
+       struct vki_xen_translate_gpfn_list *memory_reservation =
+           (struct vki_xen_translate_gpfn_list *)ARG2;
+       POST_MEM_WRITE((Addr)&memory_reservation->mfn_list,
+                      sizeof(vki_xen_pfn_t) * memory_reservation->nr_gpfns);
+       break;
+   }
    }
 }
 
@@ -1444,6 +1635,35 @@ POST(domctl){
 #undef __POST_XEN_DOMCTL_WRITE
 }
 
+POST(sched_op)
+{
+   unsigned long op = ARG1;
+   //void *arg = (void *)(unsigned long)ARG2;
+
+#define __POST_XEN_SCHEDOP_WRITE(_sched_op, _type, _field)  \
+      POST_MEM_WRITE((Addr)&((_type*)arg)->_field,      \
+                     sizeof(((_type*)arg)->_field))
+#define POST_XEN_SCHEDOP_WRITE(_sched_op, _field) \
+      __POST_XEN_SCHEDOP_READ(_sched_op, struct vki_xen_sched_ ## _sched_op, _field)
+
+   switch (op) {
+   case VKI_XEN_SCHEDOP_yield:
+   case VKI_XEN_SCHEDOP_block:
+   case VKI_XEN_SCHEDOP_shutdown:
+   case VKI_XEN_SCHEDOP_poll:
+   case VKI_XEN_SCHEDOP_remote_shutdown:
+   case VKI_XEN_SCHEDOP_shutdown_code:
+   case VKI_XEN_SCHEDOP_watchdog:
+      /* No ouput. */
+      break;
+   default:
+      break;
+   }
+
+#undef POST_XEN_SCHEDOP_WRITE
+#undef __POST_XEN_SCHEDOP_WRITE
+}
+
 POST(hvm_op)
 {
    unsigned long op = ARG1;
@@ -1472,6 +1692,38 @@ POST(hvm_op)
    case VKI_XEN_HVMOP_get_mem_access:
       POST_XEN_HVMOP_WRITE(get_mem_access, hvmmem_access);
       break;
+   case VKI_XEN_HVMOP_set_isa_irq_level:
+   case VKI_XEN_HVMOP_set_pci_link_route:
+   case VKI_XEN_HVMOP_modified_memory:
+   case VKI_XEN_HVMOP_set_mem_type:
+   case VKI_XEN_HVMOP_pagetable_dying:
+   case VKI_XEN_HVMOP_xentrace:
+   case VKI_XEN_HVMOP_set_mem_access:
+   case VKI_XEN_HVMOP_inject_trap:
+      /* No output parameter */
+      break;
+
+   case VKI_XEN_HVMOP_track_dirty_vram:
+      POST_XEN_HVMOP_WRITE(track_dirty_vram, dirty_bitmap);
+      break;
+
+   case VKI_XEN_HVMOP_get_time:
+      POST_XEN_HVMOP_WRITE(get_time, now);
+      break;
+
+   case VKI_XEN_HVMOP_register_ioreq_server:
+      POST_XEN_HVMOP_WRITE(register_ioreq_server, id);
+      break;
+
+   case VKI_XEN_HVMOP_get_ioreq_server_buf_channel:
+      POST_XEN_HVMOP_WRITE(get_ioreq_server_buf_channel, channel);
+      break;
+
+   case VKI_XEN_HVMOP_map_io_range_to_ioreq_server:
+   case VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server:
+   case VKI_XEN_HVMOP_register_pcidev:
+      /* No output parameter */
+      break;
    }
 #undef __POST_XEN_HVMOP_WRITE
 #undef POST_XEN_HVMOP_WRITE
@@ -1544,7 +1796,7 @@ static XenHypercallTableEntry hypercall_
    HYPXY(__VKI_XEN_mmuext_op,               mmuext_op,         2), // 26
    //    __VKI_XEN_xsm_op                                          // 27
    //    __VKI_XEN_nmi_op                                          // 28
-   //    __VKI_XEN_sched_op                                        // 29
+   HYPXY(__VKI_XEN_sched_op,                sched_op,          2), // 29
 
    //    __VKI_XEN_callback_op                                     // 30
    //    __VKI_XEN_xenoprof_op                                     // 31
diff -rupN valgrind-3.10.1.orig/include/Makefile.am valgrind-3.10.1/include/Makefile.am
--- valgrind-3.10.1.orig/include/Makefile.am	2015-05-08 14:48:32.950977029 -0400
+++ valgrind-3.10.1/include/Makefile.am	2015-05-08 14:50:21.028977017 -0400
@@ -73,6 +73,7 @@ nobase_pkginclude_HEADERS = \
 	vki/vki-scnums-mips64-linux.h	\
 	vki/vki-scnums-darwin.h         \
 	vki/vki-xen.h                   \
+	vki/vki-xen-sched.h		\
 	vki/vki-xen-domctl.h		\
 	vki/vki-xen-evtchn.h		\
 	vki/vki-xen-gnttab.h		\
diff -rupN valgrind-3.10.1.orig/include/vki/vki-linux.h valgrind-3.10.1/include/vki/vki-linux.h
--- valgrind-3.10.1.orig/include/vki/vki-linux.h	2015-05-08 14:48:32.942977029 -0400
+++ valgrind-3.10.1/include/vki/vki-linux.h	2015-05-08 14:50:21.029977017 -0400
@@ -3234,11 +3234,17 @@ struct vki_xen_privcmd_mmapbatch_v2 {
         int __user *err;  /* array of error codes */
 };
 
+struct vki_xen_privcmd_mmapcacheattr {
+	__vki_u64 addr;
+	int type;
+};
+
 #define VKI_XEN_IOCTL_PRIVCMD_HYPERCALL    _VKI_IOC(_VKI_IOC_NONE, 'P', 0, sizeof(struct vki_xen_privcmd_hypercall))
 #define VKI_XEN_IOCTL_PRIVCMD_MMAP         _VKI_IOC(_VKI_IOC_NONE, 'P', 2, sizeof(struct vki_xen_privcmd_mmap))
 
 #define VKI_XEN_IOCTL_PRIVCMD_MMAPBATCH    _VKI_IOC(_VKI_IOC_NONE, 'P', 3, sizeof(struct vki_xen_privcmd_mmapbatch))
 #define VKI_XEN_IOCTL_PRIVCMD_MMAPBATCH_V2 _VKI_IOC(_VKI_IOC_NONE, 'P', 4, sizeof(struct vki_xen_privcmd_mmapbatch_v2))
+#define VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR	_VKI_IOC(_VKI_IOC_NONE, 'P', 200, sizeof (struct vki_xen_privcmd_mmapcacheattr))
 
 //----------------------------------------------------------------------
 // Xen evtchn IOCTL
diff -rupN valgrind-3.10.1.orig/include/vki/vki-xen-domctl.h valgrind-3.10.1/include/vki/vki-xen-domctl.h
--- valgrind-3.10.1.orig/include/vki/vki-xen-domctl.h	2015-05-08 14:48:32.945977029 -0400
+++ valgrind-3.10.1/include/vki/vki-xen-domctl.h	2015-05-08 14:50:21.029977017 -0400
@@ -86,6 +86,7 @@
 #define VKI_XEN_DOMCTL_getnodeaffinity               69
 #define VKI_XEN_DOMCTL_set_max_evtchn                70
 #define VKI_XEN_DOMCTL_cacheflush                    71
+#define VKI_XEN_DOMCTL_iommu_map_batch		     94
 #define VKI_XEN_DOMCTL_gdbsx_guestmemio            1000
 #define VKI_XEN_DOMCTL_gdbsx_pausevcpu             1001
 #define VKI_XEN_DOMCTL_gdbsx_unpausevcpu           1002
@@ -275,6 +276,18 @@ struct vki_xen_domctl_settimeoffset {
     vki_int32_t time_offset_seconds;
 };
 
+struct vki_xen_domctl_iommu_map_batch {
+    vki_xen_uint64_aligned_t gfn;
+    vki_xen_uint64_aligned_t nr;
+    VKI_XEN_GUEST_HANDLE_64(vki_uint64) mfns;
+};
+
+struct vki_xen_domctl_pin_mem_cacheattr {
+    vki_xen_uint64_aligned_t start;
+    vki_xen_uint64_aligned_t end;
+    vki_uint32_t type;
+};
+
 struct vki_xen_domctl_cpuid {
   vki_uint32_t input[2];
   vki_uint32_t eax;
@@ -349,6 +362,10 @@ struct vki_xen_domctl_cacheflush {
     vki_xen_pfn_t start_pfn, nr_pfns;
 };
 
+struct vki_xen_domctl_assign_device {
+    vki_uint32_t machine_sbdf;
+};
+
 struct vki_xen_domctl {
     vki_uint32_t cmd;
     vki_uint32_t interface_version; /* XEN_DOMCTL_INTERFACE_VERSION */
@@ -386,11 +403,11 @@ struct vki_xen_domctl {
         struct vki_xen_domctl_address_size      address_size;
         //struct vki_xen_domctl_sendtrigger       sendtrigger;
         //struct vki_xen_domctl_get_device_group  get_device_group;
-        //struct vki_xen_domctl_assign_device     assign_device;
+        struct vki_xen_domctl_assign_device     assign_device;
         //struct vki_xen_domctl_bind_pt_irq       bind_pt_irq;
         //struct vki_xen_domctl_memory_mapping    memory_mapping;
         //struct vki_xen_domctl_ioport_mapping    ioport_mapping;
-        //struct vki_xen_domctl_pin_mem_cacheattr pin_mem_cacheattr;
+        struct vki_xen_domctl_pin_mem_cacheattr pin_mem_cacheattr;
         //struct vki_xen_domctl_ext_vcpucontext   ext_vcpucontext;
         //struct vki_xen_domctl_set_target        set_target;
         //struct vki_xen_domctl_subscribe         subscribe;
diff -rupN valgrind-3.10.1.orig/include/vki/vki-xen-hvm.h valgrind-3.10.1/include/vki/vki-xen-hvm.h
--- valgrind-3.10.1.orig/include/vki/vki-xen-hvm.h	2015-05-08 14:48:32.941977029 -0400
+++ valgrind-3.10.1/include/vki/vki-xen-hvm.h	2015-05-08 14:50:21.029977017 -0400
@@ -26,6 +26,23 @@ struct vki_xen_hvm_set_pci_link_route {
 };
 typedef struct vki_xen_hvm_set_pci_link_route vki_xen_hvm_set_pci_link_route_t;
 
+#define VKI_XEN_HVMOP_track_dirty_vram    6
+struct vki_xen_hvm_track_dirty_vram {
+    vki_xen_domid_t  domid;                             /* IN */
+    vki_xen_uint64_aligned_t first_pfn;                 /* IN */
+    vki_xen_uint64_aligned_t nr;                        /* IN */
+    VKI_XEN_GUEST_HANDLE_64(vki_uint8) dirty_bitmap;    /* OUT */
+};
+typedef struct kvi_xen_hvm_track_dirty_vram vki_xen_hvm_track_dirty_vram_t;
+
+#define VKI_XEN_HVMOP_modified_memory    7
+struct vki_xen_hvm_modified_memory {
+    vki_xen_domid_t  domid;             /* IN */
+    vki_xen_uint64_aligned_t first_pfn; /* IN */
+    vki_xen_uint64_aligned_t nr;        /* IN */
+};
+typedef struct kvi_xen_hvm_modified_memory vki_xen_hvm_modified_memory_t;
+
 #define VKI_XEN_HVMOP_set_mem_type 8
 struct vki_xen_hvm_set_mem_type {
     vki_xen_domid_t  domid;
@@ -35,6 +52,29 @@ struct vki_xen_hvm_set_mem_type {
 };
 typedef struct vki_xen_hvm_set_mem_type vki_xen_hvm_set_mem_type_t;
 
+#define VKI_XEN_HVMOP_pagetable_dying        9
+struct vki_xen_hvm_pagetable_dying {
+    vki_xen_domid_t  domid;         /* IN */
+    vki_uint16_t pad[3];            /* align next field on 8-byte boundary */
+    vki_uint64_t gpa;               /* IN */
+};
+typedef struct vki_xen_hvm_pagetable_dying vki_xen_hvm_pagetable_dying_t;
+
+#define VKI_XEN_HVMOP_get_time              10
+struct vki_xen_hvm_get_time {
+    vki_uint64_t now;   /* OUT */
+};
+typedef struct vki_xen_hvm_get_time vki_xen_hvm_get_time_t;
+
+#define VKI_XEN_HVMOP_xentrace              11
+struct vki_xen_hvm_xentrace {
+    vki_uint16_t event;                                                     /* IN */
+    vki_uint16_t extra_bytes;                                               /* IN */
+#define __XEN_HVM_TRACE_EXTRA_MAX 7
+    vki_uint8_t extra[__XEN_HVM_TRACE_EXTRA_MAX * sizeof(vki_uint32_t)];    /* IN */
+};
+typedef struct vki_xen_hvm_xentrace vki_xen_hvm_xentrace_t;
+
 #define VKI_XEN_HVMOP_set_mem_access        12
 struct vki_xen_hvm_set_mem_access {
     vki_xen_domid_t domid;
@@ -64,6 +104,55 @@ struct vki_xen_hvm_inject_trap {
 };
 typedef struct vki_xen_hvm_inject_trap vki_xen_hvm_inject_trap_t;
 
+/* Handle identifying the ioreq server. */
+typedef vki_uint32_t vki_xen_ioservid_t;
+
+#define VKI_XEN_HVMOP_register_ioreq_server 20
+struct vki_xen_hvm_register_ioreq_server {
+    vki_xen_domid_t domid;  /* IN */
+    vki_xen_ioservid_t id;  /* OUT */
+};
+typedef struct vki_xen_hvm_register_ioreq_server vki_xen_hvm_register_ioreq_server_t;
+
+#define VKI_XEN_HVMOP_get_ioreq_server_buf_channel 21
+struct vki_xen_hvm_get_ioreq_server_buf_channel {
+    vki_xen_domid_t domid;          /* IN */
+    vki_xen_ioservid_t id;          /* IN */
+    vki_xen_evtchn_port_t channel;  /* OUT */
+};
+typedef struct vki_xen_hvm_get_ioreq_server_buf_channel vki_xen_hvm_get_ioreq_server_buf_channel_t;
+
+#define VKI_XEN_HVMOP_map_io_range_to_ioreq_server 22
+struct vki_xen_hvm_map_io_range_to_ioreq_server {
+    vki_xen_domid_t domid;      /* IN */
+    vki_uint8_t is_mmio;        /* IN */
+    vki_xen_ioservid_t id;      /* IN */
+    vki_xen_uint64_aligned_t s; /* IN */
+    vki_xen_uint64_aligned_t e; /* IN */
+};
+typedef struct vki_xen_hvm_map_io_range_to_ioreq_server vki_xen_kvm_map_io_range_to_ioreq_server_t;
+
+
+#define VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server 23
+struct vki_xen_hvm_unmap_io_range_from_ioreq_server {
+    vki_xen_domid_t domid;          /* IN */
+    vki_uint8_t is_mmio;            /* IN */
+    vki_xen_ioservid_t id;          /* IN */
+    vki_xen_uint64_aligned_t addr;  /* IN */
+};
+typedef struct vki_xen_hvm_unmap_io_range_from_ioreq_server vki_xen_hvm_unmap_iorange_from_ioreq_server_t;
+
+#define VKI_XEN_HVMOP_register_pcidev 24
+struct vki_xen_hvm_register_pcidev {
+    vki_xen_domid_t domid;  /* IN */
+    vki_xen_ioservid_t id;  /* IN */
+    vki_uint16_t domain;    /* IN */
+    vki_uint8_t bus;        /* IN */
+    vki_uint8_t device;     /* IN */
+    vki_uint8_t function;   /* IN */
+};
+typedef struct vki_xen_hvm_register_pcidev vki_xen_hvm_register_pcidev_t;
+
 #endif // __VKI_XEN_HVM_H
 
 /*--------------------------------------------------------------------*/
diff -rupN valgrind-3.10.1.orig/include/vki/vki-xen-memory.h valgrind-3.10.1/include/vki/vki-xen-memory.h
--- valgrind-3.10.1.orig/include/vki/vki-xen-memory.h	2015-05-08 14:48:32.942977029 -0400
+++ valgrind-3.10.1/include/vki/vki-xen-memory.h	2015-05-08 14:50:58.262977012 -0400
@@ -22,6 +22,18 @@
 #define VKI_XENMEM_get_sharing_shared_pages   19
 #define VKI_XENMEM_access_op                  21
 #define VKI_XENMEM_claim_pages                24
+#define VKI_XENMEM_translate_gpfn_list	29
+#define VKI_XENMEM_release_mfn_list	30
+
+struct vki_xen_translate_gpfn_list {
+    /* IN parameters */
+    vki_xen_domid_t domid;
+    vki_xen_ulong_t nr_gpfns;
+    VKI_XEN_GUEST_HANDLE(vki_xen_pfn_t) gpfn_list;
+    /* OUT parameter */
+    VKI_XEN_GUEST_HANDLE(vki_xen_pfn_t) mfn_list;
+};
+
 
 struct vki_xen_memory_map {
     unsigned int nr_entries;
diff -rupN valgrind-3.10.1.orig/include/vki/vki-xen-sched.h valgrind-3.10.1/include/vki/vki-xen-sched.h
--- valgrind-3.10.1.orig/include/vki/vki-xen-sched.h	1969-12-31 19:00:00.000000000 -0500
+++ valgrind-3.10.1/include/vki/vki-xen-sched.h	2015-05-08 14:50:21.029977017 -0400
@@ -0,0 +1,35 @@
+#ifndef __VKI_XEN_SCHED_H
+#define __VKI_XEN_SCHED_H
+
+#define VKI_XEN_SCHEDOP_yield           0
+#define VKI_XEN_SCHEDOP_block           1
+#define VKI_XEN_SCHEDOP_shutdown        2
+struct vki_xen_sched_shutdown {
+   unsigned int reason;
+};
+
+#define VKI_XEN_SCHEDOP_poll            3
+struct vki_xen_sched_poll {
+   VKI_XEN_GUEST_HANDLE(vki_xen_evtchn_port_t) ports;
+   unsigned int nr_ports;
+   vki_uint64_t timeout;
+};
+
+#define VKI_XEN_SCHEDOP_remote_shutdown 4
+struct vki_xen_sched_remote_shutdown {
+   vki_xen_domid_t domain_id;
+   unsigned int reason;
+};
+
+#define VKI_XEN_SCHEDOP_shutdown_code   5
+#define VKI_XEN_SCHEDOP_watchdog        6
+struct vki_xen_sched_watchdog {
+   vki_uint32_t id;
+   vki_uint32_t timeout;
+};
+
+
+#endif	// __VKI_XEN_SCHED_H
+/*--------------------------------------------------------------------*/
+/*--- end                                                          ---*/
+/*--------------------------------------------------------------------*/
diff -rupN valgrind-3.10.1.orig/include/vki/vki-xen.h valgrind-3.10.1/include/vki/vki-xen.h
--- valgrind-3.10.1.orig/include/vki/vki-xen.h	2015-05-08 14:48:32.946977029 -0400
+++ valgrind-3.10.1/include/vki/vki-xen.h	2015-05-08 14:50:21.029977017 -0400
@@ -85,6 +85,7 @@ struct vki_xenctl_bitmap {
 #include <vki/vki-xen-gnttab.h>
 #include <vki/vki-xen-version.h>
 #include <vki/vki-xen-hvm.h>
+#include <vki/vki-xen-sched.h>
 #include <vki/vki-xen-tmem.h>
 
 #endif // __VKI_XEN_H
